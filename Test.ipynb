{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "#the parameters of the buildTree function take as parameters:\n",
    "    #D which is the input Data (Records)\n",
    "    #dic which is the dictionnary that correspands each attribute to an index (example dic['A']=0)\n",
    "    #Attributes contains the values that can be taken by each attribute (exp Attributes[0] contains \n",
    "                                                                    #the values that can be taken by the attribute 'A')\n",
    "    #A is a list of all the attributes\n",
    "    #node is the position of the node in the tree\n",
    "    #lvl is the level of the corresponding node\n",
    "    \n",
    "def BuildTree(D,dic,Attributes,A,minNum,node,lvl,d,tree):\n",
    "    # tree[node] = [-1 if not leaf and class if leaf , level, Feature , GINI]\n",
    "    GINI_split = 0 # the GINI of The corresponding node\n",
    "    ma = 0 #used to maximize information gain\n",
    "    \n",
    "    res = '';\n",
    "    \n",
    "    splitAtt = 0; #the best attribute we will chose to split the tree\n",
    "    \n",
    "    if (len(A)==0): # if we finished splitting the tree then the node will be a leaf\n",
    "                    # and will take all the records in the same class\n",
    "        tree[node] = (D[0][len(D[0])-1],lvl,\"\",0)\n",
    "        return;\n",
    "    if len(D)<minNum: # if the number of records <minNum the the node will be a leaf take the class d (default)\n",
    "            tree[node] = (d,lvl,\"\",0)\n",
    "            return\n",
    "    for a in A: # iterate attributes to find the best split\n",
    "        Att=dic[a] # the index of the corresponding attribute in the input data\n",
    "        test = True # to check if all records have the same class\n",
    "        clas = D[0][len(D[0])-1] # class of the first record\n",
    "        L = Attributes[Att] # the possible values that the attribute can take\n",
    "        C1 = [0 for co in range(len(L))] # holds for each possible value the number of records having class 0\n",
    "        C2 = [0 for co in range(len(L))] # holds for each possible value the number of records having class 1\n",
    "        for rec in D:\n",
    "            if rec[len(D[0])-1]==0:\n",
    "                C1[rec[Att]]+=1\n",
    "            else:\n",
    "                C2[rec[Att]]+=1\n",
    "\n",
    "            if (rec[len(D[0])-1]!=clas):\n",
    "                test = False\n",
    "        \n",
    "        if (test): # if all records have same class the node is a leaf with the same class\n",
    "            tree[node] = (clas,lvl,\"\",0)\n",
    "            return\n",
    "\n",
    "        \n",
    "        for spli in range(1,len(L)): # spli is the index of the split\n",
    "                spl1=L[0:spli] # spl1 values to the left\n",
    "                spl2=L[spli:]  # spl2 values to the right\n",
    "                \n",
    "                c01 = sum(C1) # number of records having class =0 in the node\n",
    "                c02 = sum(C2) # number of records having class =1 in the node\n",
    "                c11 = sum(C1[0:spli]) # number of records having class =0 in the left child\n",
    "                c12 = sum(C2[0:spli]) # number of records having class =1 in the left child\n",
    "                c21 = sum(C1[spli:]) # number of records having class =0 in the right child\n",
    "                c22 = sum(C2[spli:]) # number of records having class =1 in the right child\n",
    "                \n",
    "               \n",
    "                EntropyP = 0;Entropy1=0;Entropy2=0; # Entropy1 is the entropy of the left child and Entropy2 of the right child\n",
    "                                                    # EntropyP is the entropy of the parent\n",
    "                \n",
    "                if (c01+c02)!=0 and (c01/(c01+c02))!=0: # for no log2(0)\n",
    "                    EntropyP-= (c01/(c01+c02)) * log2((c01/(c01+c02))) \n",
    "                if (c01+c02)!=0 and (c02/(c01+c02))!=0:\n",
    "                    EntropyP-= (c02/(c01+c02)) * log2((c02/(c01+c02)))\n",
    "                if (c11+c12)!=0 and (c11/(c11+c12))!=0:\n",
    "                    Entropy1 = -1 * (c11/(c11+c12)) * log2((c11/(c11+c12))) \n",
    "                if (c11+c12)!=0 and (c12/(c11+c12))!=0:\n",
    "                    Entropy1-= (c12/(c11+c12)) * log2((c12/(c11+c12)))\n",
    "                if (c21+c22)!=0 and (c22/(c21+c22))!=0:\n",
    "                    Entropy2 = -1 * (c22/(c21+c22)) * log2((c22/(c21+c22))) \n",
    "                if (c21+c22)!=0 and (c21/(c21+c22))!=0:\n",
    "                    Entropy2-= (c21/(c21+c22)) * log2((c21/(c21+c22)))\n",
    "                Entropy_split = EntropyP - (Entropy1 * ((c11+c12)/(c11+c12+c22+c21)) + Entropy2*((c21+c22)/(c11+c12+c22+c21)))\n",
    "                if (Entropy_split>=ma): #maximizing the information gain\n",
    "                    ma = Entropy_split\n",
    "                    res = spli\n",
    "                    splitAtt = a\n",
    "                    GINI1=0;GINI2=0\n",
    "                    if (c11+c12)!=0:\n",
    "                        GINI1=1-(c11/(c11+c12))**2-(c12/(c11+c12))**2\n",
    "                    if (c21+c22)!=0:\n",
    "                        GINI2=1-(c22/(c21+c22))**2-(c21/(c21+c22))**2\n",
    "                    GINI_split = GINI1 * ((c11+c12)/(c11+c12+c22+c21)) + GINI2*((c21+c22)/(c11+c12+c22+c21))\n",
    "\n",
    "    right = [] #records to the right\n",
    "    left=[]    #records to the left\n",
    "    \n",
    "    L=Attributes[dic[splitAtt]] #index of the chosen attribute that maximizes info gain\n",
    "    \n",
    "    for i in D:\n",
    "        if i[dic[splitAtt]] in L[0:res]:\n",
    "            left.append(i)\n",
    "        else:\n",
    "            right.append(i)\n",
    "    \n",
    "    st = splitAtt # st is the string of the feature example 'A 0 1'\n",
    "   \n",
    "    for ss in L[0:res]:\n",
    "        st+=\" \"\n",
    "        st+=str(ss) \n",
    "    tree[node]=(-1,lvl,st,GINI_split) #finally setting the node to the chosen values\n",
    "    LL = A.copy()\n",
    "    LL.pop(LL.index(splitAtt)) # deleting the used attribute from the set of attributes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #recursive call for right and left child\n",
    "    BuildTree(left,dic,Attributes,LL,minNum,node*2+1,lvl+1,d,tree) \n",
    "    BuildTree(right,dic,Attributes,LL,minNum,node*2+2,lvl+1,d,tree)\n",
    "    \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildDecisionTree(D,dic,Attributes,A,minNum,node,lvl,d):\n",
    "    tree=[() for i in range(2**(len(Attributes)+1))] # the resulting tree passed as global var to BuildTree\n",
    "    # tree[node] = [-1 if not leaf and class if leaf , level, Feature , GINI]\n",
    "    BuildTree(D,dic,Attributes,A,minNum,node,lvl,d,tree)\n",
    "    return tree\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTree(tree):\n",
    "    #print tree BFS\n",
    "    \n",
    "    q=[]\n",
    "    q.append(0)\n",
    "    while(len(q)>0):\n",
    "        node = q.pop(0)\n",
    "        t = tree[node]\n",
    "        \n",
    "        if (node==0):\n",
    "            if (t[0]==-1): # if node is root but not leaf\n",
    "                print(\"Root\")\n",
    "                print(\"Level\",t[1])\n",
    "                print(\"Feature\",t[2] )\n",
    "                print(\"Gini\",t[3])\n",
    "                q.append(node*2+1)\n",
    "                q.append(node*2+2)\n",
    "            else : # if tree has only one node\n",
    "                print(\"Root/leaf\")\n",
    "                print(\"Level\",t[1])\n",
    "                \n",
    "                print(\"Gini\",t[3])\n",
    "                \n",
    "        else:\n",
    "            if (t[0]==-1): # if node is not leaf\n",
    "                print(\"Intermediate\")\n",
    "                print(\"Level\",t[1])\n",
    "                print(\"Feature :\",t[2] )\n",
    "                print(\"Gini\",t[3])\n",
    "                q.append(node*2+1)\n",
    "                q.append(node*2+2)\n",
    "            else: # if node is leaf\n",
    "                print(\"Leaf\")\n",
    "                print(\"Level\",t[1])\n",
    "                print(\"Gini\",t[3])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters are :\n",
    "    # data is the input data in the format list[list[int]]\n",
    "    # dic is the dictionnary linking each attribute to an index\n",
    "    # tree is the resulting tree from BuildDecisionTree (heap Tree)\n",
    "    # alpha is float\n",
    "def error(data,dic,tree,alpha):\n",
    "    num_leaves = 0 # number of leaves in tree\n",
    "    num_errors=0   # number of wrong predictions for the data set\n",
    "    for i in range(len(tree)): # counting the leaves\n",
    "        if len(tree[i])==0:\n",
    "            continue\n",
    "        if  tree[i][0]!=-1:\n",
    "            num_leaves+=1\n",
    "            \n",
    "    testTree = [[] for k in range(len(tree))] # testTree is the tree containing the records at each node\n",
    "    \n",
    "    testTree[0] = data # the root has all the records \n",
    "    \n",
    "    for i in range(len(tree)):\n",
    "        if len(tree[i])==0:\n",
    "            continue\n",
    "        node = tree[i]\n",
    "        if (node[0]==-1): ## node is not leaf\n",
    "            condition = node[2].split(\" \") # node 2 is like \"A 0 1 2\"\n",
    "            At = condition[0] ## tested attribute\n",
    "            values = [int(x) for x in condition[1:]] \n",
    "            # if the value of the tested data of the corresponding attribute is in values then we go left else we go right\n",
    "            for prod in testTree[i]:\n",
    "                if prod[dic[At]] in values:\n",
    "                    testTree[i*2+1].append(prod)\n",
    "                else :\n",
    "                    testTree[i*2+2].append(prod)\n",
    "        \n",
    "        else : # if node is a leaf\n",
    "            \n",
    "            for prod in testTree[i]: \n",
    "                # for each record in the node of testTree we check if its class is equal to the predicted class\n",
    "                if prod[len(prod)-1]!=node[0]:\n",
    "                    num_errors+=1 # if class[prod] is not equal to the predicted class then we add 1 to error\n",
    "    genErr = num_errors+alpha*num_leaves\n",
    "    return  genErr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters are :\n",
    "    # data is the input data in the format list[list[int]]\n",
    "    # dic is the dictionnary linking each attribute to an index\n",
    "    # tree is the resulting tree from BuildDecisionTree (heap Tree)\n",
    "    # alpha is float\n",
    "    # minNum is int \n",
    "    # d is the default class (binary)\n",
    "def prune(data,dic,tree,alpha, minNum, d):\n",
    " \n",
    "    testTree = [ [] for k in range(len(tree))] # same as with error function we built the test tree\n",
    "    testTree[0] = data\n",
    "    for i in range(len(tree)): \n",
    "        if len(tree[i])==0:\n",
    "            continue\n",
    "        node = tree[i]\n",
    "        if (node[2]!=\"\"): ## node is not leaf\n",
    "            condition = node[2].split(\" \")\n",
    "            At = condition[0] ## tested attribute\n",
    "            values = [int(x) for x in condition[1:]]\n",
    "            for prod in testTree[i]:\n",
    "                if prod[dic[At]] in values:\n",
    "                    testTree[i*2+1].append(prod)\n",
    "                else :\n",
    "                    testTree[i*2+2].append(prod)\n",
    "    \n",
    "    pruned = [tt for tt in tree] # pruned is the result of this function it starts the same as tree\n",
    "    err = error(data,dic,tree,alpha) # compute the generalization error of the tree \n",
    "    \n",
    "    for i in range(len(tree)-1,-1,-1): # starting from the last node (MaxLvl downto 0)\n",
    "        if len(pruned[i])==0:\n",
    "            continue\n",
    "        node = pruned[i] # node of the pruned tree (starting from last node)\n",
    "        temp = [xx for xx in pruned] # temp is the temporary tree where we try to prune and see the result\n",
    "        if len(node)>0 and node[0]==-1: #if node is not leaf\n",
    "            records = testTree[i] # the records contained in the corresponding node (=num records left child+num records right child)\n",
    "            if len(records)<minNum: # if number of records <minNum we prune with the default class d\n",
    "                temp[i] = (d,tree[i][1],\"\",0) # the node becomes a leaf with class d\n",
    "                temp[2*i+1]=[] #delete left and right child\n",
    "                temp[2*i+2]=[]\n",
    "                tempErr = error(data,dic,temp,alpha) # compute gen error of the temp tree\n",
    "                if (tempErr<err): # minimizing the err\n",
    "                    pruned = temp # if tempErr < err then we prune and update err\n",
    "                    err = tempErr\n",
    "            else:\n",
    "                cla1 = 0;cla2 = 0;\n",
    "                # cla1 number of records having the class 0 and cla2 number of records having the class 1\n",
    "                for record in records: #counting\n",
    "                    if record[len(record)-1]==0:\n",
    "                        cla1+=1\n",
    "                    else :\n",
    "                        cla2+=1\n",
    "                        \n",
    "                if cla1>cla2: # then the node is a leaf with class 0\n",
    "                    temp[i] = (0,tree[i][1],\"\",0)\n",
    "                    temp[2*i+1]=[]\n",
    "                    temp[2*i+2]=[]\n",
    "                    tempErr = error(data,dic,temp,alpha)# compute gen error of the temp tree\n",
    "                    if (tempErr<err):# if tempErr < err then we prune and update err\n",
    "                        pruned = temp\n",
    "                        err = tempErr\n",
    "                    \n",
    "                else : # then the node is a leaf with class 1\n",
    "                    temp[i] = (1,tree[i][1],\"\",0)\n",
    "                    temp[2*i+1]=()\n",
    "                    temp[2*i+2]=()\n",
    "                    tempErr = error(data,dic,temp,alpha)# compute gen error of the temp tree\n",
    "                    if (tempErr<err):# if tempErr < err then we prune and update err\n",
    "                        pruned = temp\n",
    "                        err = tempErr\n",
    "    print(\"the generalization error of the pruned tree is = \",err) # printing the gen error\n",
    "    \n",
    "    return pruned \n",
    "\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "printing the decision tree\n",
      "-------------------------------------------------------------\n",
      "Root\n",
      "Level 1\n",
      "Feature A 0 1\n",
      "Gini 0.35714285714285715\n",
      "Intermediate\n",
      "Level 2\n",
      "Feature : C 0\n",
      "Gini 0.31999999999999984\n",
      "Leaf\n",
      "Level 2\n",
      "Gini 0\n",
      "Intermediate\n",
      "Level 3\n",
      "Feature : D 0\n",
      "Gini 0.2\n",
      "Intermediate\n",
      "Level 3\n",
      "Feature : D 0\n",
      "Gini 0.26666666666666666\n",
      "Leaf\n",
      "Level 4\n",
      "Gini 0\n",
      "Intermediate\n",
      "Level 4\n",
      "Feature : B 0 1\n",
      "Gini 0.0\n",
      "Intermediate\n",
      "Level 4\n",
      "Feature : B 0 1\n",
      "Gini 0.3333333333333333\n",
      "Leaf\n",
      "Level 4\n",
      "Gini 0\n",
      "Leaf\n",
      "Level 5\n",
      "Gini 0\n",
      "Leaf\n",
      "Level 5\n",
      "Gini 0\n",
      "Leaf\n",
      "Level 5\n",
      "Gini 0\n",
      "Leaf\n",
      "Level 5\n",
      "Gini 0\n",
      "-------------------------------------------------------------\n",
      "the generalisation error of this tree is : \n",
      "4.5\n",
      "-------------------------------------------------------------\n",
      "pruning the tree\n",
      "-------------------------------------------------------------\n",
      "the generalization error of the pruned tree is =  3.5\n",
      "Root\n",
      "Level 1\n",
      "Feature A 0 1\n",
      "Gini 0.35714285714285715\n",
      "Intermediate\n",
      "Level 2\n",
      "Feature : C 0\n",
      "Gini 0.31999999999999984\n",
      "Leaf\n",
      "Level 2\n",
      "Gini 0\n",
      "Intermediate\n",
      "Level 3\n",
      "Feature : D 0\n",
      "Gini 0.2\n",
      "Leaf\n",
      "Level 3\n",
      "Gini 0\n",
      "Leaf\n",
      "Level 4\n",
      "Gini 0\n",
      "Intermediate\n",
      "Level 4\n",
      "Feature : B 0 1\n",
      "Gini 0.0\n",
      "Leaf\n",
      "Level 5\n",
      "Gini 0\n",
      "Leaf\n",
      "Level 5\n",
      "Gini 0\n"
     ]
    }
   ],
   "source": [
    "f = open(\"text.txt\",'r').read().strip().split(\"\\n\")\n",
    "A=['A','B','C','D'] ## names of attributes we suppose that this is the same order as the input file.txt\n",
    "\n",
    "Attributes = [[0,1,2],[0,1,2],[0,1],[0,1]] # values taken by attributes\n",
    "\n",
    "dic={} # correspands each attribute to an index\n",
    "inde = 0;\n",
    "## indexing the attributes\n",
    "for a in A:\n",
    "    dic[a]=inde\n",
    "    inde+=1\n",
    "\n",
    "lis = [i.split(\" \") for i in f] # in format List[List[string]]\n",
    "ll=[] # the input converted to List[List[int]]\n",
    "\n",
    "for i in lis:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        temp.append(int(j))\n",
    "    ll.append(temp)\n",
    "\n",
    "tree = BuildDecisionTree(ll,dic,Attributes,A,0,0,1,0)\n",
    "\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print (\"printing the decision tree\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "printTree(tree)\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print(\"the generalisation error of this tree is : \")\n",
    "print(error(ll,dic,tree,0.5))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print(\"pruning the tree\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "printTree(prune(ll,dic,tree,0.5, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
